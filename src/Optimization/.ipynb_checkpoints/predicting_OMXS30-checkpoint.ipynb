{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization problem\n",
    "we would like to maximise \n",
    "$$\n",
    "\\operatorname{\\mathbb{E}_{t}}[R_{t}^{P}] - \\gamma \\operatorname{Var_{t}}[R_{t}^{P}]\n",
    "$$\n",
    "with respect to $z_{t}$, under the contraint that $\\mathbb{1}^{T}z_{t}=0$. Here, $\\gamma$, a _risk aversion parameter_ , with value $\\gamma = 1/2$.\n",
    "\n",
    "In addition, we would like to add the no short-sale constraint \n",
    "$$\n",
    "w_{t}+z_{t} \\geq 0.\n",
    "$$ \n",
    "\n",
    "Hence, we would like to pick the $z_{t}$ that solves the optimization problem\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\underset{z_{t}\\in\\mathbb{R}^{n}}{\\mathrm{maximize}}\n",
    "& & R_{t|t}^{T}z_{t} - \\gamma (w_{t}+z_{t})^{T}\\Sigma_{t|t}(w_{t}+z_{t}) \\\\\n",
    "& \\text{subject to}\n",
    "& &  \\mathbb{1}^{T}z_{t}=0, \\\\\n",
    "& & &  w_{t}+z_{t} \\geq 0, \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "for each time $t=1\\ldots,T$. However, $R_{t|t}$ and $\\Sigma_{t|t}$ are typically not know, but can be replaced by approprate estimates $\\hat R_{t|t}$ and $\\hat\\Sigma_{t|t}$, respectively. Thus, we arrive at the final problem \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\underset{z_{t}\\in\\mathbb{R}^{n}}{\\mathrm{maximize}}\n",
    "& & \\hat R_{t|t}^{T}z_{t} - \\gamma (w_{t}+z_{t})^{T}\\hat\\Sigma_{t|t}(w_{t}+z_{t}) \\\\\n",
    "& \\text{subject to}\n",
    "& &  \\mathbb{1}^{T}z_{t}=0, \\\\\n",
    "& & &  w_{t}+z_{t} \\geq 0, \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n",
    "that needs to be solved for each time $t=1\\ldots,T$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/manssandsjo/Documents/GitHub/StockBot/group-b/src/Data\n",
      "1.9404761904761905\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "os.chdir(os.path.pardir)\n",
    "%cd Data\n",
    "import investPyData as omxs30\n",
    "Rpd, N = omxs30.import_omxs30() # N number of stocks, R return between two days\n",
    "\n",
    "\n",
    "T = len(Rpd)\n",
    "R=Rpd.to_numpy()\n",
    "print(T/252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import mosek\n",
    "\n",
    "def SPO_mark(hat_R, hat_Sigma, weights, gamma):\n",
    "    z = cvx.Variable(N)\n",
    "    expected_netReturn = hat_R.T @ z # for each stock, depends on how \n",
    "    expected_risk = gamma*cvx.quad_form(weights + z, hat_Sigma) # weights.T * hat_Sigma * weights\n",
    "    \n",
    "    utility = expected_netReturn - expected_risk\n",
    "    objective = cvx.Maximize(utility)\n",
    "\n",
    "    constraints = [\n",
    "        cvx.sum(z) == 0, # difference in weights sums up to 0 – portfolio stays fully invested\n",
    "        weights + z >= 0, # no short sales\n",
    "        weights + z <= 0.3 # no more than 30% in an asset\n",
    "    ] \n",
    "    prob = cvx.Problem(objective, constraints)\n",
    "    prob.solve(solver=cvx.MOSEK)\n",
    "    \n",
    "    return z.value #change of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to loop convex optimization for each day of the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loop_optimization(calc_mu, Sigma_func, SigmaHyper, gamma):\n",
    "    totValue = np.empty(T+1)\n",
    "    totValue[0] = 1E6\n",
    "    weights = np.ones(N)/N # starting with 1/30 invested in all stocks\n",
    "    R_P = np.zeros(T) # portfolio realized return - fractional increase of portfolio return over the period\n",
    "    muTemp = R[0,:] # use the old mu value the first period of optimization & when not predicting return\n",
    "    sigma = Sigma_func(1, SigmaHyper)\n",
    "    \n",
    "    z = SPO_mark(muTemp, sigma, weights, gamma)# tSigma_func is the cov matrix of the expected returns\n",
    "    R_P[0] = R[0].T @ (weights + z)\n",
    "    totValue[1] = totValue[0] * (1 + R_P[0]) # total value of the whole portfolio\n",
    "    turnover = np.linalg.norm(z,ord=1)/2\n",
    "    \n",
    "    # Iterate over the whole period T and calculate the change of weights by maximazing\n",
    "    # the risk adjusted return of each period\n",
    "    for t in range (T-1):\n",
    "        \n",
    "        muTemp = calc_mu[t,:]\n",
    "        #estimate the cov matrix for day t\n",
    "        sigma = Sigma_func(t, SigmaHyper)\n",
    "        # solve the convex optimization problem for each day\n",
    "        weights =  (1 + R[t])*(weights + z) / (1+R_P[t]) # next period weights Boyd (2.11)\n",
    "        z = SPO_mark(muTemp, sigma, weights, gamma) #c\n",
    "\n",
    "        turnover += np.linalg.norm(z ,ord=1)/2\n",
    "        R_P[t+1] = R[t+1].T @ (weights + z) # calc the actual return from the new calc weights\n",
    "        totValue[t+2] = totValue[t+1] * (1 + R_P[t+1])\n",
    "    return totValue, turnover, R_P, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics\n",
    "Annualized average turnover is calculated by:\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{250}{T} \\sum_{t=1}^{T}\\left\\|\\left(z_{t}\\right)_{1: n}\\right\\|_{1} / 2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The _post-trade total value_ of the portfolio, in SEK, given exactly at the beginning of time period $t$, is just $v_{t}$, since\n",
    "$$\n",
    "\\mathbb{1}^{T}h_{t}^{+} = \\mathbb{1}^{T}(h_{t} + u_{t}) = \\mathbb{1}^{T}h_{t} + \\mathbb{1}^{T} u_{t} = \\mathbb{1}^{T}h_{t} = v_{t}, \\quad \\forall t = 1,\\ldots,T.\n",
    "$$\n",
    "\n",
    "Assuming that the risk-free rate is zero, the annualized sharpe ratio is given by:\n",
    "$$\n",
    "SR = \\frac{\\overline{R^{P}_{t}}}{\\widehat{\\sigma}^{P}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot and print the portfolio data\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_n_printPortfolio(totValuePrint, turnoverPrint, R_Pprint, name, weightsPrint):\n",
    "    an_turnover = (turnoverPrint/T)*252 # approx 252 trading days in a year\n",
    "\n",
    "    print('\\033[1m'+name+'\\033[0m')\n",
    "    print('Turnover:',an_turnover.round(6)); print('Total value of portfolio:', totValuePrint[T].round())\n",
    "    \n",
    "    #plot the total value of the portfolio over time T\n",
    "    fig, axes = plt.subplots()\n",
    "    years = np.arange(T+1)/252\n",
    "    axes.plot(years, totValuePrint)\n",
    "    axes.set_xlabel('Year')\n",
    "    axes.set_ylabel('SEK')\n",
    "    axes.set_title(name);\n",
    "\n",
    "\n",
    "    # print the sharpe ratio\n",
    "    # annualized average of returns\n",
    "    averageRe = np.mean(R_Pprint)*252\n",
    "    # annualized standard deviation of returns\n",
    "    stdSigma = np.std(R_Pprint)*np.sqrt(252)\n",
    "    sharpeRatio_an = (averageRe/stdSigma)\n",
    "    print('Sharpe Ratio:', sharpeRatio_an.round(6)); print('Weights at end of period', weightsPrint.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperMetrics(totValuePrint, turnoverPrint, R_Pprint):\n",
    "    an_turnover = (turnoverPrint/T)*252 # approx 252 trading days in a year\n",
    "\n",
    "    # annualized average of returns\n",
    "    averageRe = np.mean(R_Pprint)*252\n",
    "    # annualized standard deviation of returns\n",
    "    stdSigma = np.std(R_Pprint)*np.sqrt(252)\n",
    "    sharpeRatio_an = (averageRe/stdSigma)\n",
    "    return an_turnover, sharpeRatio_an"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_calc_v1(t, T_SCM):\n",
    "    R_Sigma = R.copy()\n",
    "    Sigma = np.zeros((N,N))\n",
    "    \n",
    "    if t-T_SCM < 0:\n",
    "            Sigma = np.dot(R_Sigma[t-1].reshape((N,1)),R_Sigma[t-1].reshape((1,N)))\n",
    "            return Sigma\n",
    "    \n",
    "    for i in range (t-T_SCM,t):\n",
    "        \n",
    "        Sigma += np.dot(R_Sigma[i].reshape((N,1)),R_Sigma[i].reshape((1,N)))\n",
    "    Sigma = Sigma/T_SCM\n",
    "    return Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ledoit & Wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Manu föreslår assume_centered = True, tveksamt om det funkar som intended dock\n",
    "#DENNA KÖR PÅ HELA INTERVALLET OCH TAR EJ HÄNSYN TILL span, span används för att sätta assume centered eller ej\n",
    "def Ledoit_Wolf(t,ass_centered):\n",
    "    R_Sigma = R.copy()\n",
    "    from sklearn.covariance import LedoitWolf  \n",
    "    \n",
    "    if t <= 5:\n",
    "        Sigma = np.dot(R_Sigma[t-1].reshape((N,1)),R_Sigma[t-1].reshape((1,N)))\n",
    "        return Sigma\n",
    "        \n",
    "    cov = LedoitWolf(assume_centered=ass_centered).fit(R_Sigma[0:t-1,:])\n",
    "\n",
    "    return cov.covariance_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple moving average\n",
    "$ SMA = \\frac{A^n_1+A^n_2+...+A^n_t}{T}$\n",
    "<br>Where $A^n_t =$ the return of the stock $n$ at period $t$\n",
    "<br> $T =$ number of periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcSMA(Tsma):\n",
    "    df_Rsma = Rpd.copy()\n",
    "\n",
    "    for col in Rpd.columns:\n",
    "        # to calculate first Tsma periods set min_periods = 1\n",
    "        # for instance the 2nd day then becomes the first days real value, 3rd day mean of 1st and 2nd real returns\n",
    "        df_Rsma[col] = Rpd[col].shift(1).rolling(Tsma, min_periods = 1).mean() # shift 1 to calc from yesterdays values\n",
    "    df_Rsma = df_Rsma.iloc[1:]\n",
    "    return df_Rsma.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Moving Average\n",
    "Exponential moving average gives more weight to the recent prices and as a result of which, it can be a better model or better capture the movement of the trend in a faster way. EMA's reaction is directly proportional to the pattern of the data.\n",
    "\n",
    "Let $\\alpha_{\\text{EMA}}\\in (0,1)$ and\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\hat R_{t|t}^{\\text{EMA}} = \n",
    "    \\begin{cases}\n",
    "    R_{t-1},              & \\text{if } t = 2, \\\\\n",
    "    \\alpha_{\\text{EMA}} \\hat R_{t-1|t-1}^{\\text{EMA}} + (1 - \\alpha_{\\text{EMA}}) R_{t-1},              & \\text{if } 2 < t \\leq T.\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$\n",
    "Often, a variable $\\tau_{\\text{EMA}}\\in\\mathbb{N}$ is introduced such that \n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\alpha_{\\text{EMA}} = 1 - \\frac{1}{\\tau_{\\text{EMA}} + 1},\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcEMA(span):\n",
    "    df_Rema = Rpd.copy()\n",
    "    for index in df_Rema.index[:T-1]:\n",
    "        if index <= 2:\n",
    "            df_Rema.iloc[index] = Rpd.iloc[index-1]\n",
    "        else:\n",
    "            df_Rema.iloc[index] = df_Rema.iloc[index-1].ewm(span=span,adjust=False).mean()\n",
    "            R_ewm = df_Rema.to_numpy()\n",
    "            \n",
    "    return R_ewm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper optimization for SMA & SCM\n",
    "between 2010-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hyperDataFrameSMA = pd.DataFrame(columns=['Tsma','SigmaHyper','Gamma','Turnover','SharpeRatio'])\n",
    "\n",
    "for Tsma in np.logspace(1,5,num =4, base=2, dtype='int'):\n",
    "    print('TSma', Tsma)\n",
    "    for SigmaHyper in np.logspace(1,4,num =4, base=2, dtype='int'):\n",
    "        print('SigmaHyper', SigmaHyper)\n",
    "        for gamma in np.logspace(-1,11,num =7, base=2, dtype='float'): \n",
    "            totValueSMA, turnoverSMA, R_Psma, weightsSMA = loop_optimization(\n",
    "                calcSMA(Tsma), \n",
    "                covariance_calc_v1, \n",
    "                SigmaHyper,\n",
    "                gamma)\n",
    "            turnOver, sharpeR = hyperMetrics(totValueSMA, turnoverSMA, R_Psma)\n",
    "            hyperDataFrameSMA = hyperDataFrameSMA.append({'Tsma': Tsma, 'SigmaHyper': SigmaHyper, 'Gamma': gamma, 'Turnover': turnOver,'SharpeRatio': sharpeR}, ignore_index=True)\n",
    "\n",
    "hyperDataFrameSMA.head(100)\n",
    "hyperDataFrameSMA.to_pickle('./pickle_hyper/hyperDataFrameSMA_SCM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opSMApd = pd.read_pickle('./pickle_hyper/hyperDataFrameSMA_SCM.pkl')\n",
    "hyperDataSMAsort = opSMApd[(opSMApd['SharpeRatio'] > 0) ]\n",
    "hyperDataSMAsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper optimization for EMA and SCM\n",
    "between 2010-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperDataFrameEMA = pd.DataFrame(columns=['T_ema','SigmaHyper','Gamma','Turnover','SharpeRatio'])\n",
    "\n",
    "for T_ema in np.logspace(3,8, num =5, base=2, dtype='int'):\n",
    "    print('T_ema', T_ema)\n",
    "    for SigmaHyper in np.logspace(1,4,num =4, base=2, dtype='int'):\n",
    "        print('SigmaHyper', SigmaHyper)\n",
    "        for gamma in np.logspace(-1,11,num =7, base=2, dtype='float'): \n",
    "            totValueEMA, turnoverEMA, R_Pema, weightsEMA = loop_optimization(\n",
    "                calcEMA(T_ema), \n",
    "                covariance_calc_v1, \n",
    "                SigmaHyper,\n",
    "                gamma)\n",
    "            turnOver, sharpeR = hyperMetrics(totValueEMA, turnoverEMA, R_Pema)\n",
    "            hyperDataFrameEMA = hyperDataFrameEMA.append({'T_ema': T_ema, 'SigmaHyper': SigmaHyper, 'Gamma': gamma, \n",
    "                                                          'Turnover': turnOver,'SharpeRatio': sharpeR}, ignore_index=True)\n",
    "\n",
    "hyperDataFrameEMA.to_pickle('./pickle_hyper/hyperDataFrameEMA_SCM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opEMApd = pd.read_pickle('./pickle_hyper/hyperDataFrameEMA_SCM.pkl')\n",
    "hyperDataEMAsort = opEMApd[(opEMApd['SharpeRatio'] > 0) & (opEMApd['Turnover'] < 82 )]\n",
    "opEMApd.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "LSTMs are widely used for sequence prediction problems and have proven to be extremely effective. The reason they work so well is because LSTM is able to store past information that is important, and forget the information that is not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLSTM(model, stock, iterDays, sc):\n",
    "# vill uppdatera LSTM datan ofta för att få bra prediktion typ rullande varje dag\n",
    "    #trYrs = len(R)-30;\n",
    "    \n",
    "    # make predictions 1 day at a time\n",
    "    predDays = 1\n",
    "    #day_of_pred = trYrs+iterDays\n",
    "    # retrieve last observations for input data and feed with known days continously\n",
    "    inputs = stock\n",
    "    # reshape into [1, input, 1]\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs  = sc.transform(inputs)\n",
    "    inputs = inputs.reshape((1,len(inputs),1))\n",
    "    #print(inputs)\n",
    "    \n",
    "    '''\n",
    "    X_test = []  \n",
    "\n",
    "    # predict next 5 days\n",
    "    for i in range(predDays,len(inputs)):\n",
    "        X_test.append(inputs[i-predDays:i,0])\n",
    "        \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "    print(np.shape(X_test))'''\n",
    "\n",
    "\n",
    "    rets_pred = model.predict(inputs,verbose=1) \n",
    "\n",
    "    rets_pred = sc.inverse_transform(rets_pred)\n",
    "\n",
    "\n",
    "    \n",
    "    return rets_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vill uppdatera LSTM datan ofta för att få bra prediktion typ rullande varje dag\n",
    "\n",
    "Run data and create models for each of the stocks\n",
    "\n",
    "ändra successivt historiken av data som matas till predictLSTM med 1 dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# glöm inte ändra investpy range från 2016-2018\n",
    "# load LSTM models from Data/keras_models\n",
    "os.chdir(os.path.pardir)\n",
    "%cd Data\n",
    "\n",
    "ndaysPred = len(R)\n",
    "dfLSTM = pd.DataFrame(np.zeros((ndaysPred, N)))\n",
    "predValue = 0\n",
    "\n",
    "# loop over the stocks denna tar typ 20-30 min för alla stocks\n",
    "for stock in range (N):\n",
    "    # load saved model for stock\n",
    "    model = keras.models.load_model('keras_models/model_2010_2016_'+str(stock))\n",
    "    # load saved scaler\n",
    "    sc = pickle.load(open('scaler.pkl'+str(stock),'rb'))\n",
    "    print(stock) # to see progress\n",
    "    \n",
    "    #create prediction for ndaysPred for that stock\n",
    "    for day in range (1,ndaysPred): \n",
    "        # save historical data for model as previous day\n",
    "        stockHist = Rpd.iloc[day-1,stock]\n",
    "        # predict next day's return\n",
    "        predValue = predictLSTM(model, stockHist, day, sc)\n",
    "        # save to R_hat vect\n",
    "        dfLSTM.iloc[day,stock] = predValue\n",
    "        \n",
    "dfLSTM.to_pickle('./pickle_hyper/R_lstm_2018_2020.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totValueSMA, turnoverSMA, R_Psma, weightsSMA = loop_optimization(dfR_LSTM.to_numpy(), covariance_calc_v1)\n",
    "#print(R_Psma)\n",
    "plot_n_printPortfolio(totValueSMA, turnoverSMA, R_Psma, 'LSTM Predicted Portfolio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Optimization LSTM & SCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the LSTM model as fixed, since we don't have the required computing power \n",
    "# to hyper optimize the parameters for LSTM\n",
    "R_LSTM = pd.read_pickle('./pickle_hyper/R_lstm_2016_2018.pkl').to_numpy()\n",
    "\n",
    "hyperDataFrameLSTM_SCM = pd.DataFrame(columns=['T_SCM','Gamma','Turnover','SharpeRatio'])\n",
    "\n",
    "for SigmaHyper in np.logspace(1,4,num =4, base=2, dtype='int'):\n",
    "    print('SigmaHyper', SigmaHyper)\n",
    "    for gamma in np.logspace(-1,11,num =7, base=2, dtype='float'): #7\n",
    "        totValueSMA, turnoverSMA, R_Psma, weightsSMA = loop_optimization(\n",
    "            R_LSTM, \n",
    "            covariance_calc_v1, \n",
    "            SigmaHyper,\n",
    "            gamma)\n",
    "        turnOver, sharpeR = hyperMetrics(totValueSMA, turnoverSMA, R_Psma)\n",
    "        hyperDataFrameLSTM_SCM = hyperDataFrameLSTM_SCM.append({'T_SCM': SigmaHyper, 'Gamma': gamma, 'Turnover': turnOver,'SharpeRatio': sharpeR}, ignore_index=True)\n",
    "\n",
    "hyperDataFrameLSTM_SCM.to_pickle('./pickle_hyper/hyperDataFrameLSTM_SCM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opLSTM_SCMpd = pd.read_pickle('./pickle_hyper/hyperDataFrameLSTM_SCM.pkl')\n",
    "hyperDataLSTM_SCMsort = opLSTM_SCMpd[(opLSTM_SCMpd['SharpeRatio'] > 0) & (opLSTM_SCMpd['Turnover'] < 82 )]\n",
    "hyperDataLSTM_SCMsort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper optimization LSTM & LW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Viewing the LSTM model as fixed, since we don't have the required computing power \n",
    "# to hyper optimize the parameters for LSTM\n",
    "R_LSTM = pd.read_pickle('./pickle_hyper/R_lstm_2016_2018.pkl').to_numpy()\n",
    "\n",
    "hyperDataFrameLSTM_LW = pd.DataFrame(columns=['SigmaHyper','Gamma','Turnover','SharpeRatio'])\n",
    "\n",
    "for SigmaHyper in range(0,2):\n",
    "    print('SigmaHyper', SigmaHyper)\n",
    "    if(SigmaHyper == 0):\n",
    "        SigmaHyper = False\n",
    "    if(SigmaHyper == 1):\n",
    "        SigmaHyper = True\n",
    "    for gamma in np.logspace(-1,11,num =7, base=2, dtype='float'): #7\n",
    "        totValueSMA, turnoverSMA, R_Psma, weightsSMA = loop_optimization(\n",
    "                R_LSTM, \n",
    "                Ledoit_Wolf, \n",
    "                SigmaHyper,\n",
    "                gamma)\n",
    "        turnOver, sharpeR = hyperMetrics(totValueSMA, turnoverSMA, R_Psma)\n",
    "        hyperDataFrameLSTM_LW = hyperDataFrameLSTM_LW.append({'SigmaHyper': SigmaHyper, 'Gamma': gamma, 'Turnover': turnOver,'SharpeRatio': sharpeR}, ignore_index=True)\n",
    "\n",
    "\n",
    "hyperDataFrameLSTM_LW.to_pickle('./pickle_hyper/hyperDataFrameLSTM_LW.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opLSTM_LWpd = pd.read_pickle('./pickle_hyper/hyperDataFrameLSTM_LW.pkl')\n",
    "hyperDataLSTM_LWsort = opLSTM_LWpd[(opLSTM_LWpd['SharpeRatio'] > -0.55)]\n",
    "hyperDataLSTM_LWsort\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of selected hyperparameters\n",
    "### SMA & SCM\n",
    "Best performance 2010-2018 for T_SMA = 32.0, T_SCM = 8.0, Gamma = 512.0\t\n",
    "gave turnover = 82.137790,\tSR = 0.102309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312    9.205950\n",
       "313    0.000000\n",
       "314   -0.015766\n",
       "Name: R, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weird bug with R vector. Has a value of 9 when using date 2018-2020, replace this value with the value from day before\n",
    "Rpd.iloc[311:314,-4]\n",
    "Rpd.iloc[311,-4] = Rpd.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totValueSMA_SCM, turnoverSMA_SCM, R_Psma_scm, w = loop_optimization(calcSMA(32),covariance_calc_v1, 8, 512)\n",
    "\n",
    "plot_n_printPortfolio(totValueSMA_SCM, turnoverSMA_SCM, R_Psma_scm, 'SMA & SCM Predicted Portfolio', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMA & SCM\n",
    "Best performance from 2010-2018 for T_ema = 8.0,\tT_scm = 8.0, Gamma = 2.0\t\n",
    "gave turnover = 81.548874, SR = 0.315238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Rpd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totValueEMA_SCM, turnoverEMA_SCM, R_Pema_scm, w = loop_optimization(calcEMA(8),\n",
    "                                                                 covariance_calc_v1,\n",
    "                                                                 SigmaHyper = 8,\n",
    "                                                                 gamma = 2)\n",
    "\n",
    "plot_n_printPortfolio(totValueEMA_SCM, turnoverEMA_SCM, R_Pema_scm, 'EMA & SCM Predicted Portfolio',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM & SCM\n",
    "Best performance from 2016-2018 for T_scm = 8.0, Gamma = 512.0,\n",
    "    gave turnover = 67.623572, SR = 0.285660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_lstm2018_20 = pd.read_pickle('./pickle_hyper/R_lstm_2018_2020.pkl').to_numpy()\n",
    "\n",
    "totValueLSTM_SCM, turnoverLSTM_SCM, R_Plstm_scm, w = loop_optimization(R_lstm2018_20,\n",
    "                                                                 covariance_calc_v1,\n",
    "                                                                 SigmaHyper = 8,\n",
    "                                                                 gamma = 512)\n",
    "\n",
    "plot_n_printPortfolio(totValueLSTM_SCM, turnoverLSTM_SCM, R_Plstm_scm, 'LSTM & SCM Predicted Portfolio', w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM & LW\n",
    "Best performance from 2016-2018 for SigmaHyper = True, Gamma = 8.0,\n",
    "    gave turnover = 24.546262,\tSR = -0.520952"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_lstm2018_20 = pd.read_pickle('./pickle_hyper/R_lstm_2018_2020.pkl').to_numpy()\n",
    "\n",
    "totValueLSTM_LW, turnoverLSTM_LW, R_Plstm_lw, w = loop_optimization(R_lstm2018_20,\n",
    "                                                                 Ledoit_Wolf,\n",
    "                                                                 SigmaHyper = True,\n",
    "                                                                 gamma = 8)\n",
    "\n",
    "plot_n_printPortfolio(totValueLSTM_LW, turnoverLSTM_LW, R_Plstm_lw, 'LSTM & LW Predicted Portfolio', w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
